# Explainable AI

![img](https://github.com/dominodatalab/domino-reference-project-xai/blob/master/scratch/blackbox.png?raw=true)

Model interpretability is a seminal topic in the field of data science. 
The field is moving quickly. Practitioners can leverage a range of tools to provide 
explainability to their models from traditional approaches to the latests in deep neural 
network explainers.

## Project Contents

This project contains starter code for a few of these approaches and some educational material on xAI.

* [SHAP_and_LIME.ipynb](./view/SHAP_and_LIME.ipynb)  -  a how-to notebook
* [rtemis.R](./view/rtemis.R)  -  a how-to R file
* [traditional_methods.ipynb](./view/traditional_methods.ipynb)  -  a how-to notebook
* [Navigating Interpretable and Predictive Models.pdf](./view/Navigating+Interpretable+and+Predictive+Models.pdf)  -  slides from the tech talk on xAI which includes many links to further research

## Suggested Actions

* Explore the SHAP_and_LIME.ipynb notebook

## Reference Material

* Learn more about xAI by browsing the instructional pdf
* updaetd project files can be found at [https://github.com/dominodatalab/domino-reference-project-xai](https://github.com/dominodatalab/domino-reference-project-xai)

## Prerequisites

This project uses standard python libraries and any base python install should work well. The Python libraries *shap*, *lime*, and *pycebox* will probably need to be installed separately. 

There are several additional R libraries needed to run *rtemis*. This library changes frequently, sometimes breaking dependencies. See the R scipt included in this project for details.
